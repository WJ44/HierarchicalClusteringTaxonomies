{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster import hierarchy\n",
    "from keras.models import Sequential\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = './data/All'\n",
    "\n",
    "\n",
    "def preprocess(images, labels):\n",
    "    return tf.keras.applications.resnet50.preprocess_input(images), labels\n",
    "\n",
    "\n",
    "img_height, img_width = 320, 240\n",
    "batch_size = 64\n",
    "\n",
    "print('Loading dataset')\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=0,\n",
    "    label_mode='categorical',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size, )\n",
    "\n",
    "class_names = dataset.class_names\n",
    "class_name_map = {}\n",
    "for i in range(len(class_names)):\n",
    "    class_name_map[i] = class_names[i]\n",
    "\n",
    "print('Preprocessing')\n",
    "dataset = dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "\n",
    "pretrained_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "                                                  input_shape=(320, 240, 3),\n",
    "                                                  pooling='avg',\n",
    "                                                  weights='imagenet')\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "resnet_model.add(pretrained_model)\n",
    "\n",
    "y = []\n",
    "features = []\n",
    "\n",
    "model = resnet_model\n",
    "\n",
    "print('Extracting features')\n",
    "for samples, labels in tqdm(dataset):\n",
    "    predictions = model.predict(samples, verbose=0)\n",
    "    features.extend(predictions)\n",
    "    y.extend(labels)\n",
    "\n",
    "X = pd.DataFrame(features)\n",
    "y = np.argmax(y, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X['Label'] = y\n",
    "X['Label'] = X['Label'].map(class_name_map)\n",
    "categories = X.groupby('Label').mean()\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('Clustering')\n",
    "\n",
    "linkage='single'\n",
    "\n",
    "n_clusters = 12\n",
    "\n",
    "clustering = AgglomerativeClustering(compute_distances=True, n_clusters=n_clusters, linkage=linkage)\n",
    "clusters = clustering.fit_predict(categories)\n",
    "\n",
    "no_of_observations = np.arange(2, clustering.children_.shape[0]+2)\n",
    "linkage_matrix = np.column_stack([clustering.children_, clustering.distances_, no_of_observations]).astype(float)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "hierarchy.dendrogram(linkage_matrix, labels=class_names, leaf_font_size=8, color_threshold=0, truncate_mode='lastp', p=n_clusters)\n",
    "plt.show()\n",
    "\n",
    "cluster_map = {}\n",
    "for i in range(len(class_names)):\n",
    "    cluster_map[i] = clusters[i]\n",
    "    print(f'{class_names[i]}: cluster {clusters[i]}')\n",
    "X['Label'] = y\n",
    "X['Label'] = X['Label'].map(cluster_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(X.drop('Label', axis=1), X['Label'])\n",
    "print(\"silhouette_avg:\", silhouette_avg)\n",
    "\n",
    "sample_silhouette_values = silhouette_samples(X.drop('Label', axis=1), X['Label'])\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 8)\n",
    "ax1.set_xlim([-1, 1])\n",
    "ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters):\n",
    "    cluster_silhouette_values = sample_silhouette_values[X['Label'] == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    size_cluster = cluster_silhouette_values.shape[0]\n",
    "\n",
    "    y_upper = size_cluster + y_lower\n",
    "    color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster, str(i))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticks([-1, -0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "silhouette_scores = pd.DataFrame(columns=['Silhouette', 'y', 'difference'])\n",
    "linkage_matrix = None\n",
    "n_cuts = 3\n",
    "\n",
    "linkage='single'\n",
    "\n",
    "for n in range(2,13):\n",
    "    print(n)\n",
    "    n_clusters = n\n",
    "\n",
    "    clustering = AgglomerativeClustering(compute_distances=True, n_clusters=n_clusters, linkage=linkage)\n",
    "    clusters = clustering.fit_predict(categories)\n",
    "\n",
    "    no_of_observations = np.arange(2, clustering.children_.shape[0]+2)\n",
    "    linkage_matrix = np.column_stack([clustering.children_, clustering.distances_, no_of_observations]).astype(float)\n",
    "\n",
    "    cluster_map = {}\n",
    "    for i in range(len(class_names)):\n",
    "        cluster_map[i] = clusters[i]\n",
    "        # print(f'{class_names[i]}: cluster {clusters[i]}')\n",
    "    X['Label'] = y\n",
    "    X['Label'] = X['Label'].map(cluster_map)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X.drop('Label', axis=1), X['Label'])\n",
    "    print(\"silhouette_avg:\", silhouette_avg)\n",
    "\n",
    "    if n == 12:\n",
    "        silhouette_scores.loc[n] = [silhouette_avg, (linkage_matrix[12-n][2] - 0)/2 + 0, linkage_matrix[12-n][2]]\n",
    "        fig, ax1 = plt.subplots()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        hierarchy.dendrogram(linkage_matrix, labels=class_names, leaf_font_size=8, color_threshold=0, truncate_mode='lastp', p=n_clusters, ax=ax1, distance_sort=True, leaf_rotation=45)\n",
    "        ax2 = ax1.twiny()\n",
    "        ax2.axis('off')\n",
    "        ax2.set_xlim(-0.05,0.05)\n",
    "        ax2.barh(silhouette_scores['y'].to_numpy(), silhouette_scores['Silhouette'].to_numpy(), height=linkage_matrix[0][2]/20, color=(1, 0, 0, 0.5))\n",
    "\n",
    "        # only show best cuts\n",
    "        silhouette_scores = silhouette_scores.nlargest(n_cuts, ['difference'])\n",
    "        silhouette_scores.sort_index(inplace=True, ascending=True)\n",
    "\n",
    "        for row in silhouette_scores.itertuples():\n",
    "            ax2.axhline(y=row.y, color=(1, 0, 0, 0.5))\n",
    "            ax2.text(y=row.y, x=1.05, s=round(row.Silhouette, 4), fontsize='x-small')\n",
    "\n",
    "        ax2.plot()\n",
    "\n",
    "    else:\n",
    "        silhouette_scores.loc[n] = [silhouette_avg, (linkage_matrix[12-n][2] - linkage_matrix[12-n-1][2])/2 + linkage_matrix[12-n-1][2], linkage_matrix[12-n][2] - linkage_matrix[12-n-1][2]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-19T14:50:03.331258800Z",
     "start_time": "2023-07-19T14:50:02.805261900Z"
    },
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(silhouette_scores)\n",
    "\n",
    "filename = './aggolomerativeOntologySingle.json'\n",
    "\n",
    "splits = {}\n",
    "split = n\n",
    "largest_y = 0\n",
    "for row in linkage_matrix:\n",
    "    splits[split] = [[row[0], row[1]], row[2]]\n",
    "    largest_y = row[2]\n",
    "    split += 1\n",
    "print(splits, split)\n",
    "print(linkage_matrix)\n",
    "\n",
    "levels = []\n",
    "for i in range(n_cuts):\n",
    "    cut = silhouette_scores['y'].iloc[i]\n",
    "    splits_copy = {}\n",
    "    for key, split in splits.items():\n",
    "        if largest_y >= split[1] > cut:\n",
    "            children = split[0]\n",
    "            split_copy = copy.deepcopy(split)\n",
    "            splits_copy[key] = split_copy\n",
    "            for child in children:\n",
    "                if child in splits.keys() and largest_y >= splits[child][1] > cut:\n",
    "                    if child in splits_copy.keys():\n",
    "                        split_copy[0].extend(splits_copy[child][0])\n",
    "                        splits_copy.pop(child)\n",
    "                    else:\n",
    "                        split_copy[0].extend(splits[child][0])\n",
    "                    split_copy[0].remove(child)\n",
    "    levels.append(splits_copy)\n",
    "    largest_y = cut\n",
    "\n",
    "print(levels)\n",
    "ontology = {}\n",
    "ontology[\"name\"] = \"dataset\"\n",
    "children = {}\n",
    "ontology[\"children\"] = children\n",
    "for key, split in levels[0].items():\n",
    "    for child in split[0]:\n",
    "        children[child] = {}\n",
    "print(ontology)\n",
    "\n",
    "def update_ontology(level, parent):\n",
    "    for child in parent:\n",
    "        if child in levels[level].keys():\n",
    "            for sub_child in levels[level][child][0]:\n",
    "                parent[child][sub_child] = {}\n",
    "        if not parent[child]:\n",
    "            parent[child][child] = {}\n",
    "        if level+1 < n_cuts:\n",
    "            update_ontology(level+1, parent[child])\n",
    "\n",
    "update_ontology(1, ontology[\"children\"])\n",
    "print(ontology)\n",
    "\n",
    "def restructure_ontology(parent):\n",
    "    children = []\n",
    "    for key, child in parent.items():\n",
    "        sub_children = restructure_ontology(child)\n",
    "        new_child = {\"name\": str(key),\n",
    "                     \"children\": sub_children}\n",
    "        if not sub_children:\n",
    "            new_child[\"leaf\"] = class_names[int(key)]\n",
    "        children.append(new_child)\n",
    "\n",
    "    return children\n",
    "\n",
    "ontology[\"children\"] = restructure_ontology(ontology[\"children\"])\n",
    "\n",
    "with open(filename, 'w') as ontologyFile:\n",
    "    json.dump(ontology, ontologyFile, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
