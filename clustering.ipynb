{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster import hierarchy\n",
    "from keras.models import Sequential\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_dir = './data/All'\n",
    "\n",
    "\n",
    "def preprocess(images, labels):\n",
    "    return tf.keras.applications.resnet50.preprocess_input(images), labels\n",
    "\n",
    "\n",
    "img_height, img_width = 320, 240\n",
    "batch_size = 64\n",
    "\n",
    "print('Loading dataset')\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    seed=0,\n",
    "    label_mode='categorical',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size, )\n",
    "\n",
    "class_names = dataset.class_names\n",
    "class_name_map = {}\n",
    "for i in range(len(class_names)):\n",
    "    class_name_map[i] = class_names[i]\n",
    "\n",
    "print('Preprocessing')\n",
    "dataset = dataset.map(preprocess)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "\n",
    "pretrained_model = tf.keras.applications.ResNet50(include_top=False,\n",
    "                                                  input_shape=(320, 240, 3),\n",
    "                                                  pooling='avg',\n",
    "                                                  weights='imagenet')\n",
    "for layer in pretrained_model.layers:\n",
    "    layer.trainable = False\n",
    "resnet_model.add(pretrained_model)\n",
    "\n",
    "y = []\n",
    "features = []\n",
    "\n",
    "model = resnet_model\n",
    "\n",
    "print('Extracting features')\n",
    "for samples, labels in tqdm(dataset):\n",
    "    predictions = model.predict(samples, verbose=0)\n",
    "    features.extend(predictions)\n",
    "    y.extend(labels)\n",
    "\n",
    "X = pd.DataFrame(features)\n",
    "y = np.argmax(y, axis=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X['Label'] = y\n",
    "X['Label'] = X['Label'].map(class_name_map)\n",
    "categories = X.groupby('Label').mean()\n",
    "categories.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Clustering')\n",
    "\n",
    "n_clusters = 12\n",
    "\n",
    "clustering = AgglomerativeClustering(compute_distances=True, n_clusters=n_clusters, linkage='single')\n",
    "clusters = clustering.fit_predict(categories)\n",
    "\n",
    "no_of_observations = np.arange(2, clustering.children_.shape[0]+2)\n",
    "linkage_matrix = np.column_stack([clustering.children_, clustering.distances_, no_of_observations]).astype(float)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "hierarchy.dendrogram(linkage_matrix, labels=class_names, leaf_font_size=8, color_threshold=0, truncate_mode='lastp', p=n_clusters)\n",
    "plt.show()\n",
    "\n",
    "cluster_map = {}\n",
    "for i in range(len(class_names)):\n",
    "    cluster_map[i] = clusters[i]\n",
    "    print(f'{class_names[i]}: cluster {clusters[i]}')\n",
    "X['Label'] = y\n",
    "X['Label'] = X['Label'].map(cluster_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_avg = silhouette_score(X.drop('Label', axis=1), X['Label'])\n",
    "print(\"silhouette_avg:\", silhouette_avg)\n",
    "\n",
    "sample_silhouette_values = silhouette_samples(X.drop('Label', axis=1), X['Label'])\n",
    "\n",
    "fig, (ax1) = plt.subplots(1, 1)\n",
    "fig.set_size_inches(8, 8)\n",
    "ax1.set_xlim([-1, 1])\n",
    "ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "y_lower = 10\n",
    "for i in range(n_clusters):\n",
    "    cluster_silhouette_values = sample_silhouette_values[X['Label'] == i]\n",
    "    cluster_silhouette_values.sort()\n",
    "    size_cluster = cluster_silhouette_values.shape[0]\n",
    "\n",
    "    y_upper = size_cluster + y_lower\n",
    "    color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    ax1.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_values, facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    ax1.text(-0.05, y_lower + 0.5 * size_cluster, str(i))\n",
    "    y_lower = y_upper + 10\n",
    "\n",
    "ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "ax1.set_yticks([])\n",
    "ax1.set_xticks([-1, -0.8, -0.6, -0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "silhouette_scores = pd.DataFrame(columns=['Silhouette', 'y', 'difference'])\n",
    "linkage_matrix = None\n",
    "n_cuts = 3\n",
    "for n in range(2,13):\n",
    "    print(n)\n",
    "    n_clusters = n\n",
    "\n",
    "    clustering = AgglomerativeClustering(compute_distances=True, n_clusters=n_clusters, linkage='average')\n",
    "    clusters = clustering.fit_predict(categories)\n",
    "\n",
    "    no_of_observations = np.arange(2, clustering.children_.shape[0]+2)\n",
    "    linkage_matrix = np.column_stack([clustering.children_, clustering.distances_, no_of_observations]).astype(float)\n",
    "\n",
    "    cluster_map = {}\n",
    "    for i in range(len(class_names)):\n",
    "        cluster_map[i] = clusters[i]\n",
    "        # print(f'{class_names[i]}: cluster {clusters[i]}')\n",
    "    X['Label'] = y\n",
    "    X['Label'] = X['Label'].map(cluster_map)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X.drop('Label', axis=1), X['Label'])\n",
    "    print(\"silhouette_avg:\", silhouette_avg)\n",
    "\n",
    "    if n == 12:\n",
    "        silhouette_scores.loc[n] = [silhouette_avg, (linkage_matrix[12-n][2] - 0)/2 + 0, linkage_matrix[12-n][2]]\n",
    "        fig, ax1 = plt.subplots()\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        hierarchy.dendrogram(linkage_matrix, labels=class_names, leaf_font_size=8, color_threshold=0, truncate_mode='lastp', p=n_clusters, ax=ax1, distance_sort=True, leaf_rotation=45)\n",
    "        ax2 = ax1.twiny()\n",
    "        ax2.axis('off')\n",
    "        ax2.set_xlim(-0.05,0.05)\n",
    "        ax2.barh(silhouette_scores['y'].to_numpy(), silhouette_scores['Silhouette'].to_numpy(), height=linkage_matrix[0][2]/20, color=(1, 0, 0, 0.5))\n",
    "\n",
    "        # only show best cuts\n",
    "        silhouette_scores = silhouette_scores.nlargest(n_cuts, ['difference'])\n",
    "        silhouette_scores.sort_index(inplace=True, ascending=True)\n",
    "\n",
    "        for row in silhouette_scores.itertuples():\n",
    "            ax2.axhline(y=row.y, color=(1, 0, 0, 0.5))\n",
    "            ax2.text(y=row.y, x=1.05, s=round(row.Silhouette, 4), fontsize='x-small')\n",
    "\n",
    "        ax2.plot()\n",
    "\n",
    "    else:\n",
    "        silhouette_scores.loc[n] = [silhouette_avg, (linkage_matrix[12-n][2] - linkage_matrix[12-n-1][2])/2 + linkage_matrix[12-n-1][2], linkage_matrix[12-n][2] - linkage_matrix[12-n-1][2]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(silhouette_scores)\n",
    "\n",
    "splits = {}\n",
    "split = n\n",
    "largest_y = 0\n",
    "for row in linkage_matrix:\n",
    "    splits[split] = [[row[0], row[1]], row[2]]\n",
    "    largest_y = row[2]\n",
    "    split += 1\n",
    "print(splits, split)\n",
    "print(linkage_matrix)\n",
    "\n",
    "levels = []\n",
    "for i in range(n_cuts):\n",
    "    cut = silhouette_scores['y'].iloc[i]\n",
    "    splits_copy = {}\n",
    "    for key, split in splits.items():\n",
    "        if largest_y >= split[1] > cut:\n",
    "            children = split[0]\n",
    "            split_copy = copy.deepcopy(split)\n",
    "            splits_copy[key] = split_copy\n",
    "            for child in children:\n",
    "                if child in splits.keys() and largest_y >= splits[child][1] > cut:\n",
    "                    if child in splits_copy.keys():\n",
    "                        split_copy[0].extend(splits_copy[child][0])\n",
    "                        splits_copy.pop(child)\n",
    "                    else:\n",
    "                        split_copy[0].extend(splits[child][0])\n",
    "                    split_copy[0].remove(child)\n",
    "    levels.append(splits_copy)\n",
    "    largest_y = cut\n",
    "\n",
    "print(levels)\n",
    "ontology = {}\n",
    "ontology[\"name\"] = \"dataset\"\n",
    "children = {}\n",
    "ontology[\"children\"] = children\n",
    "for key, split in levels[0].items():\n",
    "    for child in split[0]:\n",
    "        children[child] = {}\n",
    "print(ontology)\n",
    "\n",
    "def update_ontology(level, parent):\n",
    "    for child in parent:\n",
    "        if child in levels[level].keys():\n",
    "            for sub_child in levels[level][child][0]:\n",
    "                parent[child][sub_child] = {}\n",
    "        if not parent[child]:\n",
    "            parent[child][child] = {}\n",
    "        if level+1 < n_cuts:\n",
    "            update_ontology(level+1, parent[child])\n",
    "\n",
    "update_ontology(1, ontology[\"children\"])\n",
    "print(ontology)\n",
    "\n",
    "def restructure_ontology(parent):\n",
    "    children = []\n",
    "    for key, child in parent.items():\n",
    "        sub_children = restructure_ontology(child)\n",
    "        new_child = {\"name\": str(key),\n",
    "                     \"children\": sub_children}\n",
    "        if not sub_children:\n",
    "            new_child[\"leaf\"] = class_names[int(key)]\n",
    "        children.append(new_child)\n",
    "\n",
    "    return children\n",
    "\n",
    "ontology[\"children\"] = restructure_ontology(ontology[\"children\"])\n",
    "\n",
    "with open('./aggolomerativeOntologyAverage.json', 'w') as ontologyFile:\n",
    "    json.dump(ontology, ontologyFile, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Silhouette          y  difference\n",
      "2     0.041491  10.085392    3.610470\n",
      "10   -0.012604   4.748776    1.282844\n",
      "12   -0.015659   1.980435    3.960870\n",
      "{12: [[2.0, 8.0], 3.960870162056906], 13: [[0.0, 12.0], 4.1073543711259], 14: [[11.0, 13.0], 5.390198366833345], 15: [[3.0, 14.0], 5.658368401533796], 16: [[1.0, 4.0], 5.754297538579858], 17: [[7.0, 9.0], 5.775424470246831], 18: [[5.0, 15.0], 6.418785292267328], 19: [[6.0, 10.0], 6.992322751309263], 20: [[18.0, 19.0], 7.471324934489678], 21: [[16.0, 20.0], 8.280157280697836], 22: [[17.0, 21.0], 11.890627182528892]} 23\n",
      "[[ 2.          8.          3.96087016  2.        ]\n",
      " [ 0.         12.          4.10735437  3.        ]\n",
      " [11.         13.          5.39019837  4.        ]\n",
      " [ 3.         14.          5.6583684   5.        ]\n",
      " [ 1.          4.          5.75429754  6.        ]\n",
      " [ 7.          9.          5.77542447  7.        ]\n",
      " [ 5.         15.          6.41878529  8.        ]\n",
      " [ 6.         10.          6.99232275  9.        ]\n",
      " [18.         19.          7.47132493 10.        ]\n",
      " [16.         20.          8.28015728 11.        ]\n",
      " [17.         21.         11.89062718 12.        ]]\n",
      "[{22: [[17.0, 21.0], 11.890627182528892]}, {17: [[7.0, 9.0], 5.775424470246831], 21: [[1.0, 4.0, 5.0, 3.0, 11.0, 13.0, 6.0, 10.0], 8.280157280697836]}, {13: [[0.0, 2.0, 8.0], 4.1073543711259]}]\n",
      "{'name': 'dataset', 'children': {17.0: {}, 21.0: {}}}\n",
      "{'name': 'dataset', 'children': {17.0: {7.0: {7.0: {}}, 9.0: {9.0: {}}}, 21.0: {1.0: {1.0: {}}, 4.0: {4.0: {}}, 5.0: {5.0: {}}, 3.0: {3.0: {}}, 11.0: {11.0: {}}, 13.0: {0.0: {}, 2.0: {}, 8.0: {}}, 6.0: {6.0: {}}, 10.0: {10.0: {}}}}}\n"
     ]
    }
   ],
   "source": [
    "print(silhouette_scores)\n",
    "\n",
    "splits = {}\n",
    "split = n\n",
    "largest_y = 0\n",
    "for row in linkage_matrix:\n",
    "    splits[split] = [[row[0], row[1]], row[2]]\n",
    "    largest_y = row[2]\n",
    "    split += 1\n",
    "print(splits, split)\n",
    "print(linkage_matrix)\n",
    "\n",
    "levels = []\n",
    "for i in range(n_cuts):\n",
    "    cut = silhouette_scores['y'].iloc[i]\n",
    "    splits_copy = {}\n",
    "    for key, split in splits.items():\n",
    "        if largest_y >= split[1] > cut:\n",
    "            children = split[0]\n",
    "            split_copy = copy.deepcopy(split)\n",
    "            splits_copy[key] = split_copy\n",
    "            for child in children:\n",
    "                if child in splits.keys() and largest_y >= splits[child][1] > cut:\n",
    "                    if child in splits_copy.keys():\n",
    "                        split_copy[0].extend(splits_copy[child][0])\n",
    "                        splits_copy.pop(child)\n",
    "                    else:\n",
    "                        split_copy[0].extend(splits[child][0])\n",
    "                    split_copy[0].remove(child)\n",
    "    levels.append(splits_copy)\n",
    "    largest_y = cut\n",
    "\n",
    "print(levels)\n",
    "ontology = {}\n",
    "ontology[\"name\"] = \"dataset\"\n",
    "children = {}\n",
    "ontology[\"children\"] = children\n",
    "for key, split in levels[0].items():\n",
    "    for child in split[0]:\n",
    "        children[child] = {}\n",
    "print(ontology)\n",
    "\n",
    "def update_ontology(level, parent):\n",
    "    for child in parent:\n",
    "        if child in levels[level].keys():\n",
    "            for sub_child in levels[level][child][0]:\n",
    "                parent[child][sub_child] = {}\n",
    "        if not parent[child]:\n",
    "            parent[child][child] = {}\n",
    "        if level+1 < n_cuts:\n",
    "            update_ontology(level+1, parent[child])\n",
    "\n",
    "update_ontology(1, ontology[\"children\"])\n",
    "print(ontology)\n",
    "\n",
    "def restructure_ontology(parent):\n",
    "    children = []\n",
    "    for key, child in parent.items():\n",
    "        sub_children = restructure_ontology(child)\n",
    "        new_child = {\"name\": str(key),\n",
    "                     \"children\": sub_children}\n",
    "        if not sub_children:\n",
    "            new_child[\"leaf\"] = class_names[int(key)]\n",
    "        children.append(new_child)\n",
    "\n",
    "    return children\n",
    "\n",
    "ontology[\"children\"] = restructure_ontology(ontology[\"children\"])\n",
    "\n",
    "with open('./aggolomerativeOntologyAverage.json', 'w') as ontologyFile:\n",
    "    json.dump(ontology, ontologyFile, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-07-19T14:50:03.331258800Z",
     "start_time": "2023-07-19T14:50:02.805261900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-19T13:11:48.298703400Z",
     "start_time": "2023-07-19T13:11:47.696710Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "Python (myenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}